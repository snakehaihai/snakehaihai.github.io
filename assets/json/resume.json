{"basics":{"name":"Yuan Shenghai","label":"Scientist","image":"","email":"shyuan AT ntu.edu.sg","phone":"+65 XXXX XXXX","url":"https://snakehaihai.github.io/publications/","summary":"A Chinese-born Singaporean robotics researcher and expert, combining extensive field experience with a strong background in cutting-edge robotics research.","location":{"address":"50 Nanyang Ave, ","postalCode":"Singapore 639798","city":"Singapore","countryCode":"SG","region":"Singapore"},"profiles":[{"network":"linkedin","username":"shenghai-yuan-0613","url":"https://www.linkedin.com/in/shenghai-yuan-0613/"}]},"work":[{"name":"Nanyang Technological University","position":"Senior Research Fellow","url":"https://www.ntu.edu.sg/","startDate":"2019-11-01","endDate":"Now","summary":"Conduct research activity, writing papers, write project proposals, finish projects, writing research proposals, raising PHD kid ","highlights":["Robotics"]}],"education":[{"institution":"Nanyang Technological University, Singapore","location":"Singapore","url":"https://www.ntu.edu.sg/","area":"Robotics","studyType":"Doctor of Philosophy","startDate":"2014-01-01","endDate":"2019-01-01","score":"10","courses":["Electrical and Electronic Engineering"]},{"institution":"Nanyang Technological University, Singapore","location":"Singapore","url":"https://www.ntu.edu.sg/","area":"Robotics","studyType":"Bachelor degree","startDate":"2010-01-01","endDate":"2014-01-01","score":"10","courses":["Electrical and Electronic Engineering"]}],"awards":[{"title":"NTU Research Scholarship","date":"2014-1-01","awarder":"Nanyang Technological University, Singapore","url":"https://www.ntu.edu.sg/admissions/graduate/financialmatters/scholarships/rss","summary":"The NTU Research Scholarship is awarded to outstanding graduate students for research. "},{"title":"ICRA Conference Editorial Board Awards","date":"2024-5-10","awarder":"Nanyang Technological University, Singapore","url":"https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra/icra-ceb-awards","summary":"ICRA 2024 Conference Editorial Board Outstanding Reviewers "}],"volunteer":[{"organization":"Unmanned Systems","position":"Associate Editor","url":"https://www.worldscientific.com/worldscinet/us","startDate":"2023-12-01","endDate":"2025-12-01","summary":"Manage and oversee the peer review process to ensure it is fair, rigorous, and timely. Maintain and improve the quality of content by ensuring publications meet high academic and professional standards.","highlights":["Control the review process to be 90% within 2 months for each round of review."]},{"organization":"IEEE Conference and Journals","position":"Reviewer","url":"https://ras.papercept.net/conferences/scripts/login.pl","startDate":"2023-12-01","endDate":"2025-12-01","summary":"I critically evaluate a manuscript's quality, originality, and validity, provide constructive feedback, and recommend a decision while maintaining confidentiality and ethical standards..","highlights":["Received Best reviewer award from IEEE."]}],"publications":[{"name":"GPTR: Gaussian Process Trajectory Representation for Continuous-Time Motion Estimation","publisher":"arXiv preprint arXiv:2410.22931","releaseDate":"2024-01-01","url":"https://arxiv.org/pdf/2410.22931","summary":"This paper introduces a Gaussian Process Trajectory Representation (GPTR) framework for continuous-time motion estimation, employing a third-order random jerk model to provide smooth, continuous trajectory representations crucial for precise estimation of complex motion."},{"name":"Robust Loop Closure by Textual Cues in Challenging Environments","publisher":"arXiv preprint arXiv:2410.15869","releaseDate":"2024-01-01","url":"https://github.com/snakehaihai/TXTLCD","summary":"This study proposes a multi-modal loop closure method that leverages explicit human-readable textual cues to enhance robot navigation in featureless, degenerative, and repetitive environments."},{"name":"Compact 3D Gaussian Splatting for Dense Visual SLAM","publisher":"arXiv preprint arXiv:2403.11247","releaseDate":"2024-01-01","url":"https://arxiv.org/pdf/2403.11247","summary":"This research presents a method to reduce memory and storage costs in 3D Gaussian-based SLAM systems while maintaining high-quality scene reconstruction and rendering, utilizing techniques like sliding window-based masking and codebook-based compression."},{"name":"Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-Scale Scenes","publisher":"arXiv preprint arXiv:2404.06050","releaseDate":"2024-01-01","url":"https://arxiv.org/abs/2404.06050","summary":"This paper proposes an incremental joint learning framework that achieves accurate depth and pose estimation, along with large-scale scene reconstruction, using a monocular camera. The method employs a vision transformer-based network for enhanced scale information estimation and introduces a feature-metric bundle adjustment for robust camera tracking."},{"name":"AirSLAM: An Efficient and Illumination-Robust Point-Line Visual SLAM System","publisher":"arXiv preprint arXiv:2408.03520","releaseDate":"2024-01-01","url":"https://arxiv.org/abs/2408.03520","summary":"AirSLAM is a visual SLAM system designed to handle both short-term and long-term illumination challenges. It combines deep learning techniques for feature detection and matching with traditional backend optimization methods, utilizing a unified convolutional neural network to extract keypoints and structural lines for improved accuracy and robustness."},{"name":"Graph Optimality-Aware Stochastic LiDAR Bundle Adjustment with Progressive Spatial Smoothing","publisher":"arXiv preprint arXiv:2410.14565","releaseDate":"2024-01-01","url":"https://arxiv.org/abs/2410.14565","summary":"This study introduces PSS-GOSO, a robust, efficient, and scalable LiDAR Bundle Adjustment method. It features Progressive Spatial Smoothing for robust LiDAR feature association and Graph Optimality-aware Stochastic Optimization for efficient optimization, validated across diverse scenes for superior performance."},{"name":"GPTR: Gaussian Process Trajectory Representation for Continuous-Time Motion Estimation","publisher":"arXiv","releaseDate":"2024-10-29","url":"https://arxiv.org/pdf/2410.22931","summary":"This paper introduces GPTR, a method utilizing Gaussian Processes for continuous-time motion estimation, enhancing trajectory representation in various applications."},{"name":"Robust Loop Closure by Textual Cues in Challenging Environments","publisher":"arXiv","releaseDate":"2024-10-15","url":"https://github.com/snakehaihai/TXTLCD","summary":"The study presents a novel approach to loop closure detection by leveraging textual cues, improving robustness in challenging environments."},{"name":"Compact 3D Gaussian Splatting for Dense Visual SLAM","publisher":"arXiv","releaseDate":"2024-03-21","url":"https://arxiv.org/pdf/2403.11247","summary":"This research proposes a compact 3D Gaussian splatting technique to enhance dense visual SLAM systems, offering improved efficiency and accuracy."},{"name":"GPTR: Gaussian Process Trajectory Representation for Continuous-Time Motion Estimation","publisher":"arXiv preprint arXiv:2410.22931","releaseDate":"2024","url":"https://arxiv.org/pdf/2410.22931","summary":"This paper introduces GPTR, a method utilizing Gaussian Processes for continuous-time motion estimation, enhancing trajectory representation accuracy."},{"name":"Robust Loop Closure by Textual Cues in Challenging Environments","publisher":"arXiv preprint arXiv:2410.15869","releaseDate":"2024","url":"https://github.com/snakehaihai/TXTLCD","summary":"The study presents a novel approach to loop closure detection in SLAM systems by incorporating textual cues, improving performance in challenging environments."},{"name":"Compact 3D Gaussian Splatting for Dense Visual SLAM","publisher":"arXiv preprint arXiv:2403.11247","releaseDate":"2024","url":"https://arxiv.org/pdf/2403.11247","summary":"This research proposes a compact 3D Gaussian splatting technique to enhance dense visual SLAM, achieving efficient and accurate scene reconstruction."},{"name":"Collaborative Graph Exploration with Reduced Pose-SLAM Uncertainty via Submodular Optimization","publisher":"IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","releaseDate":"2024-10-01","url":"https://arxiv.org/abs/2407.01013","summary":"This paper proposes a collaborative graph exploration strategy to reduce pose-SLAM uncertainty in GPS-denied environments, leveraging submodular optimization for efficient exploration path planning."},{"name":"I2EKF-LO: A Dual-Iteration Extended Kalman Filter Based LiDAR Odometry","publisher":"IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","releaseDate":"2024-10-01","url":"https://arxiv.org/abs/2407.02190","summary":"Introduces I2EKF-LO, a LiDAR odometry approach using dual-iteration extended Kalman filtering to mitigate motion distortion and dynamically adjust process noise for enhanced state estimation."},{"name":"PSS-BA: LiDAR Bundle Adjustment with Progressive Spatial Smoothing","publisher":"IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","releaseDate":"2024-10-01","url":"https://arxiv.org/abs/2403.06124","summary":"PSS-BA integrates progressive spatial smoothing with LiDAR bundle adjustment to achieve robust surface constraints and accurate pose adjustments, enabling high-quality point cloud reconstruction."},{"name":"Distance-Based Multiple Noncooperative Ground Target Encirclement for Complex Environments","publisher":"IEEE Transactions on Control Systems Technology","releaseDate":"2024-01-01","url":"https://ieeexplore.ieee.org/document/10715566","summary":"This paper presents a method for multiple ground target encirclement in complex environments using distance-based strategies, providing a framework for efficient and reliable UAV operations."},{"name":"M-DIVO: Multiple ToF RGB-D Cameras Enhanced Depth-Inertial-Visual Odometry","publisher":"IEEE Internet of Things Journal","releaseDate":"2024-01-01","url":"https://ieeexplore.ieee.org/document/10612831","summary":"M-DIVO leverages multiple ToF RGB-D cameras to enhance depth-inertial-visual odometry, improving motion tracking and environmental reconstruction accuracy."},{"name":"A Fast and Light-Weight NonIterative Visual Odometry with RGB-D Cameras","publisher":"Unmanned Systems","releaseDate":"2024-01-01","url":"https://www.worldscientific.com/doi/abs/10.1142/S2301385024500013","summary":"This paper introduces a fast and lightweight visual odometry algorithm optimized for RGB-D cameras, achieving robust performance with minimal computational overhead."},{"name":"AV-FDTI: Audio-visual fusion for drone threat identification","publisher":"Journal of Automation and Intelligence","releaseDate":"2024-09-01","url":"https://hal.science/hal-04532239/","summary":"This study introduces a neural sensor fusion framework combining audio and video data to accurately detect and identify drones, enhancing security measures against illicit UAVs."},{"name":"MM-LINS: a Multi-Map LiDAR-Inertial System for Over-Degenerate Environments","publisher":"IEEE Transactions on Intelligent Vehicles","releaseDate":"2024-06-01","url":"https://ieeexplore.ieee.org/document/10557776","summary":"This paper presents MM-LINS, a multi-map LiDAR-inertial system designed to address challenges in over-degenerate environments, improving SLAM performance in complex scenarios."},{"name":"HCTO: Optimality-aware LiDAR inertial odometry with hybrid continuous-time optimization for compact wearable mapping system","publisher":"ISPRS Journal of Photogrammetry and Remote Sensing","releaseDate":"2024-03-01","url":"https://doi.org/10.1016/j.isprsjprs.2023.10.005","summary":"This research introduces HCTO, a LiDAR-inertial odometry approach utilizing hybrid continuous-time optimization, aimed at enhancing mapping accuracy in compact wearable systems."},{"name":"Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method","publisher":"IEEE International Conference on Robotics and Automation (ICRA)","releaseDate":"2024-05-13","url":"https://arxiv.org/abs/2402.05747","summary":"Introduces Jacquard V2, an enhanced robotic grasping dataset refined using a Human-In-The-Loop method to improve annotation accuracy."},{"name":"MoPA: Multi-Modal Prior Aided Domain Adaptation for 3D Semantic Segmentation","publisher":"IEEE International Conference on Robotics and Automation (ICRA)","releaseDate":"2024-05-13","url":"https://arxiv.org/abs/2309.11839","summary":"Proposes MoPA, a method leveraging multi-modal priors to enhance domain adaptation for 3D semantic segmentation, focusing on rare object classes."},{"name":"Outram: One-shot Global Localization via Triangulated Scene Graph and Global Outlier Pruning","publisher":"IEEE International Conference on Robotics and Automation (ICRA)","releaseDate":"2024-05-13","url":"https://arxiv.org/abs/2403.06124","summary":"Presents Outram, a technique for one-shot global localization using triangulated scene graphs and outlier pruning to improve accuracy."},{"name":"MMAUD: A Comprehensive Multi-Modal Anti-UAV Dataset for Modern Miniature Drone Threats","publisher":"IEEE International Conference on Robotics and Automation (ICRA)","releaseDate":"2024-05-20","url":"https://ieeexplore.ieee.org/document/10610957/","summary":"Introduces MMAUD, a dataset combining stereo vision, various Lidars, Radars, and audio arrays for UAV detection and classification."},{"name":"Eigen Is All You Need: Efficient Lidar-Inertial Continuous-Time Odometry with Internal Association","publisher":"IEEE Robotics and Automation Letters","releaseDate":"2024-06-15","url":"https://ieeexplore.ieee.org/document/10504969","summary":"Proposes SLICT2, a continuous-time lidar-inertial odometry system optimized by linear solvers for efficient performance."},{"name":"Salient Sparse Visual Odometry With Pose-Only Supervision","publisher":"IEEE Robotics and Automation Letters","releaseDate":"2024-07-10","url":"https://ieeexplore.ieee.org/document/10490100","summary":"Develops a visual odometry system that leverages salient features with pose-only supervision for improved navigation."},{"name":"A Cost-Effective Cooperative Exploration and Inspection Strategy for Heterogeneous Aerial System","publisher":"IEEE International Conference on Control and Automation (ICCA)","releaseDate":"2024-03-02","url":"https://arxiv.org/abs/2403.01225","summary":"Proposes a strategy for heterogeneous UAV swarms to perform cooperative aerial inspections without relying on precise prior environmental knowledge."},{"name":"LIO-GVM: An Accurate, Tightly-Coupled Lidar-Inertial Odometry with Gaussian Voxel Map","publisher":"IEEE Robotics and Automation Letters","releaseDate":"2024-06-01","url":"https://arxiv.org/abs/2306.17436","summary":"Introduces LIO-GVM, a framework that fuses LiDAR scans with IMU data using a tightly-coupled iterative error state Kalman filter for robust and fast localization."},{"name":"iG-LIO: An Incremental GICP-Based Tightly-Coupled LiDAR-Inertial Odometry","publisher":"IEEE Robotics and Automation Letters","releaseDate":"2024-07-01","url":"https://arxiv.org/abs/2307.12345","summary":"Presents iG-LIO, an incremental Generalized Iterative Closest Point (GICP) based method for tightly-coupled LiDAR-inertial odometry, enhancing accuracy and robustness."},{"name":"MCD: Diverse Large-Scale Multi-Campus Dataset for Robot Perception","publisher":"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition","releaseDate":"2024-06-18","url":"https://openaccess.thecvf.com/content/CVPR2024/papers/Nguyen_MCD_Diverse_Large-Scale_Multi-Campus_Dataset_for_Robot_Perception_CVPR_2024_paper.pdf","summary":"Introduces MCD, a comprehensive dataset featuring diverse environments across three Eurasian university campuses, equipped with various sensing modalities and high-accuracy ground truth data.","code":"https://mcdviral.github.io/","arxiv":"https://arxiv.org/abs/2403.11496","supplementary":"https://openaccess.thecvf.com/content/CVPR2024/supplemental/Nguyen_MCD_Diverse_Large-Scale_CVPR_2024_supplemental.pdf"},{"name":"Unmanned Aerial Vehicle and Localization Method for Unmanned Aerial Vehicle","publisher":"Google Patents","releaseDate":"2023-10-05","url":"https://patents.google.com/patent/US20230298765A1/en","summary":"Describes a novel UAV design and localization method aimed at enhancing navigation accuracy and operational efficiency in various environments."}],"skills":[{"name":"Physics","level":"Master","icon":"fa-solid fa-hashtag","keywords":["ROS","C++","Python","Machine Learning","Computer Vision"]}],"languages":[{"language":"Chinese","fluency":"Native speaker","icon":""},{"language":"English","fluency":"Fluent","icon":""}],"interests":[{"name":"Robotics","icon":"fa-solid fa-tag","keywords":["Unmanned Aerial Vehicles","Simultaneous Localization And Mapping,","Computer Vision","Point Cloud Registration","Audio Data","Benchmarking"]}],"references":[{"name":"Professor Xie Lihua","icon":"fa-solid fa-laptop","reference":"2012-Now. Email: elhxie AT ntu.edu.sg. Prof. Xie, a distinguished Fellow of IEEE, is widely recognized for his outstanding contributions to the field of engineering and technology. As my postdoc supervisor, he has been an exceptional mentor, offering invaluable guidance and support throughout numerous projects and events. His expertise and leadership have profoundly influenced my academic and professional journey. Our collaboration began in 2012, during the prestigious Million Dollar DSTA TechX Challenge, where I joined the NTU team under his mentorship. That experience not only marked the start of our professional relationship but also set the foundation for many successful endeavors together."},{"name":"Dr. Thien-Minh Nguyen","icon":"fa-solid fa-tag","reference":"2017-Now. Email: thienminh.npn  AT  ieee.org. Dr. Thien Minh is a Research Assistant Professor at Nanyang Technological University (NTU). Over the years, we have collaborated extensively, publishing numerous high-impact research papers together. Beyond being a trusted colleague, Thien Minh is also a close friend, and we often engage in productive brainstorming sessions to tackle challenging problems. Whether it’s reviewing papers, writing code, or generating ideas for new projects, we frequently rely on each other’s expertise and perspectives to refine our work and ensure the highest standards of quality and innovation.."},{"name":"Professor Wang Han","icon":"fa-solid fa-thumbtack","reference":"2012-2019. Email: HW AT ntu.edu.sg. Prof. Wang Han, my PhD supervisor, has played a pivotal role in shaping my academic journey. He has a remarkable ability to identify key research problems and has guided me through a series of impactful projects, offering me opportunities to step onto larger stages. Our connection goes back to my undergraduate years, where he first began teaching me. Our collaborative journey truly began in 2012, during the prestigious Million Dollar DSTA TechX Challenge, which laid the foundation for many achievements that followed."}]}