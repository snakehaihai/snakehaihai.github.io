<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Dr. Shenghai Yuan </title> <meta name="author" content="Dr. Shenghai Yuan"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta property="og:site_name" content="Dr. Shenghai Yuan"> <meta property="og:type" content="website"> <meta property="og:title" content="Dr. Shenghai Yuan | about"> <meta property="og:url" content="https://snakehaihai.github.io/"> <meta property="og:description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="about"> <meta name="twitter:description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Dr. Shenghai Yuan"
        },
        "url": "https://snakehaihai.github.io/",
        "@type": "WebSite",
        "description": "A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
",
        "headline": "about",
        
        "sameAs": ["https://orcid.org/0009-0003-1887-6342", "https://scholar.google.com/citations?user=XcV_sesAAAAJ", "https://www.researchgate.net/profile/Shenghai_Yuan", "https://www.scopus.com/authid/detail.uri?authorId=55827000800# your profile on Scopus", "https://www.linkedin.com/in/shenghai-yuan-0613# your LinkedIn user name", "https://dblp.org/pid/133/3411.html", "https://facebook.com/shenghai.yuan# your facebook id", "https://youtube.com/@snakehaihai# your youtube channel id (youtube.com/@<youtube_id>)"],
        
        "name": "Dr. Shenghai Yuan",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/iconsizeysh.PNG?729c60c31be75b368348f2a7483abe17"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://snakehaihai.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Dr. Shenghai</span> Yuan </h1> <p class="desc"><a href="https://www.ntu.edu.sg" rel="external nofollow noopener" target="_blank">Nanyang Technological University</a>.</p> </header> <article> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ysh-480.webp 480w,/assets/img/ysh-800.webp 800w,/assets/img/ysh-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/ysh.png?d66d5c17801f633f7da4cf6acf552332" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="ysh.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p> </p> <p> </p> <p> </p> </div> </div> <div class="clearfix"> <p>I received my B.S. and Ph.D. degrees in Electrical and Electronic Engineering in 2013 and 2019, respectively, from Nanyang Technological University, Singapore. My research focuses on robotics perception and navigation. Currently, I am a senior research fellow at the Centre for Advanced Robotics Technology Innovation (CARTIN) at Nanyang Technological University, Singapore. My research interest lies in robotics, with a focus on SLAM, sensor fusion, and autonomous navigation in challenging environments such as mines and dynamic human-robot spaces, aiming to advance adaptive and collaborative robotic systems.</p> <p>I have authored over 140 papers in top-tier journals such as TRO, IJRR, ISPRS, TIE, and RAL, as well as at prestigious conferences like ICRA, CVPR, ICCV, NeurIPS, and IROS. I also actively contribute as a reviewer for all these journals and conferences. I`ve been cited more than 2100 times as a robotics researcher. Additionally, I serve as an associate editor for the WSPC Unmanned Systems Journal and a guest editor for MDPI the Electronics Journal special issue on Advanced Technologies of Navigation for Intelligent Vehicles.</p> <p>Throughout my academic journey and professional career, I have always been passionate about mentoring and guiding others. I have had the privilege of mentoring or co-supervising over 120 undergraduate Design and Innovation project students, more than 25 undergraduate Final Year Project students, 16 Master‚Äôs students, and nine doctoral students. Beyond one-on-one mentorship, I have shared my expertise through more than five seminar talks, reaching a combined audience of over 5,000 participants, both online and in person. Currently, I am seeking an academic position where I can further contribute to education, innovation, and research in the field.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 13, 2025</th> <td> üéâ <strong>One paper has been accepted by CVPR 2025.</strong><br> Thanks to my collaborators for the great teamwork. üèÖ <strong>I have also been recognized as an Outstanding Reviewer for CVPR 2025</strong>.<br> Thanks to the CVPR community and area chairs for the recognition. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 11, 2025</th> <td> Two papers are accepted by IEEE Transactions on Robotics (TRO) </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 29, 2025</th> <td> Seven papers are accepted by ICRA 2025 </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 24, 2024</th> <td> Two papers accepted by ICASSP 2025 </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 25, 2024</th> <td> One paper ‚ÄúRobust Loop Closure by Textual Cues‚Äù is accepted by RAL </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 31, 2024</th> <td> We release the GPTR, a continuous-time trajectory representation based on gaussian process for motion estimation. Check out the <a href="https://arxiv.org/pdf/2410.22931" rel="external nofollow noopener" target="_blank">paper</a> and the <a href="https://github.com/brytsknguyen/gptr" rel="external nofollow noopener" target="_blank">source code</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 17, 2024</th> <td> I`m invited to serve as IROS chair of three sessions. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 13, 2024</th> <td> Organized and chair of IROS 2024 Workshop on Multi-Robot Perception and Navigation Challenges in Logistics and Inspection Tasks. Here are the winning teams <a href="https://ntu-aris.github.io/caric/leaderboard/#:~:text=IROS%202024%2C%20Abu%20Dhabi" rel="external nofollow noopener" target="_blank">Leaderboard</a>. Congratulations. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 22, 2024</th> <td> One paper accepted by TCST </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 29, 2024</th> <td> Four papers are accepted by IROS 2024 </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 13, 2024</th> <td> One LIO paper ‚ÄúMM-LINS‚Äù is accepted by TIV </td> </tr> <tr> <th scope="row" style="width: 20%">May 31, 2024</th> <td> <a href="https://ug2-uav-tracking.github.io/track5.html" rel="external nofollow noopener" target="_blank">Track 5</a> of the 7th UG2+ Workshop (in conjunction with CVPR 2024) has been completed. Results are available <a href="https://ug2-uav-tracking.github.io/leaderboard24_t5.html" rel="external nofollow noopener" target="_blank">Here</a>! Congratulations to all the winners! </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 05, 2024</th> <td> One paper accepted by CVPR 2024 </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 29, 2024</th> <td> Four papers are accepted by ICRA 2024 </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 27, 2023</th> <td> One paper accepted by NeurIPS 2023 </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ji2024sgba-480.webp 480w,/assets/img/publication_preview/ji2024sgba-800.webp 800w,/assets/img/publication_preview/ji2024sgba-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/ji2024sgba.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ji2024sgba.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ji2024sgba" class="col-sm-8"> <div class="title">SGBA: Semantic Gaussian Mixture Model-Based LiDAR Bundle Adjustment</div> <div class="author"> Xingyu Ji,¬†<em>Shenghai Yuan<sup>*</sup></em>,¬†Jianping Li,¬†Pengyu Yin,¬†Haozhi Cao,¬†and¬†Lihua Xie <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Corresponding&lt;br&gt;"> </i> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/LRA.2024.3479699" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2410.01618" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10715566" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/BRcSZT5LvgE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/snakehaihai/SGBA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ji2024sgba</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SGBA: Semantic Gaussian Mixture Model-Based LiDAR Bundle Adjustment}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ji, Xingyu and Yuan, Shenghai and Li, Jianping and Yin, Pengyu and Cao, Haozhi and Xie, Lihua}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2024.3479699}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/qi2024air-480.webp 480w,/assets/img/publication_preview/qi2024air-800.webp 800w,/assets/img/publication_preview/qi2024air-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/qi2024air.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="qi2024air.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="qi2024air" class="col-sm-8"> <div class="title">AIR-Embodied: An Efficient Active 3DGS-based Interaction and Reconstruction Framework with Embodied Large Language Model</div> <div class="author"> Zhenghao Qi,¬†<em>Shenghai Yuan<sup>*</sup></em>,¬†Fen Liu,¬†Haozhi Cao,¬†Tianchen Deng,¬†Jianfei Yang,¬†and¬†Lihua Xie <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Corresponding&lt;br&gt;"> </i> </div> <div class="periodical"> <em>arXiv preprint arXiv:2409.16019</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://youtu.be/GomcwBOLoEI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">qi2024air</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AIR-Embodied: An Efficient Active 3DGS-based Interaction and Reconstruction Framework with Embodied Large Language Model}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qi, Zhenghao and Yuan, Shenghai and Liu, Fen and Cao, Haozhi and Deng, Tianchen and Yang, Jianfei and Xie, Lihua}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2409.16019}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/liu2024distance-480.webp 480w,/assets/img/publication_preview/liu2024distance-800.webp 800w,/assets/img/publication_preview/liu2024distance-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/liu2024distance.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="liu2024distance.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2024distance" class="col-sm-8"> <div class="title">Distance-Based Multiple Noncooperative Ground Target Encirclement for Complex Environments</div> <div class="author"> Fen Liu,¬†<em>Shenghai Yuan<sup>*</sup></em>,¬†Kun Cao,¬†Wei Meng,¬†and¬†Lihua Xie <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Corresponding&lt;br&gt;"> </i> </div> <div class="periodical"> <em>IEEE Transactions on Control Systems Technology</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TCST.2024.3469032" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2409.15840" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10715566" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/HAtOTANfCdY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/snakehaihai/SGBA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2024distance</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distance-Based Multiple Noncooperative Ground Target Encirclement for Complex Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Fen and Yuan, Shenghai and Cao, Kun and Meng, Wei and Xie, Lihua}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Control Systems Technology}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TCST.2024.3469032}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mmaud-480.webp 480w,/assets/img/publication_preview/mmaud-800.webp 800w,/assets/img/publication_preview/mmaud-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/mmaud.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mmaud.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yuan2024MMAUD" class="col-sm-8"> <div class="title">MMAUD: A Comprehensive Multi-Modal Anti-UAV Dataset for Modern Miniature Drone Threats</div> <div class="author"> <em>Shenghai Yuan</em>,¬†Yizhuo Yang,¬†Thien Hoang Nguyen,¬†Thien-Minh Nguyen,¬†Jianfei Yang,¬†Fen Liu,¬†Jianping Li,¬†Han Wang,¬†and¬†Lihua Xie </div> <div class="periodical"> <em>In In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ICRA57147.2024.10610957" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2402.03706" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10610957/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/vdSsqYsuCPU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/ntu-aris/MMAUD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yuan2024MMAUD</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yuan, Shenghai and Yang, Yizhuo and Nguyen, Thien Hoang and Nguyen, Thien-Minh and Yang, Jianfei and Liu, Fen and Li, Jianping and Wang, Han and Xie, Lihua}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MMAUD: A Comprehensive Multi-Modal Anti-UAV Dataset for Modern Miniature Drone Threats}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2745-2751}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA57147.2024.10610957}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/nguyen2024mcds-480.webp 480w,/assets/img/publication_preview/nguyen2024mcds-800.webp 800w,/assets/img/publication_preview/nguyen2024mcds-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/nguyen2024mcds.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nguyen2024mcds.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2024mcd" class="col-sm-8"> <div class="title">Mcd: Diverse large-scale multi-campus dataset for robot perception</div> <div class="author"> Thien-Minh Nguyen,¬†<em>Shenghai Yuan<sup>*</sup></em>,¬†Thien Hoang Nguyen,¬†Pengyu Yin,¬†Haozhi Cao,¬†Lihua Xie,¬†Maciej Wozniak,¬†Patric Jensfelt,¬†Marko Thiel,¬†Justin Ziegenbein,¬†and¬† others <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Corresponding&lt;br&gt;"> </i> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2403.11496" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Nguyen_MCD_Diverse_Large-Scale_Multi-Campus_Dataset_for_Robot_Perception_CVPR_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Nguyen_MCD_Diverse_Large-Scale_CVPR_2024_supplemental.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://mcdviral.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2024mcd</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mcd: Diverse large-scale multi-campus dataset for robot perception}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Thien-Minh and Yuan, Shenghai and Nguyen, Thien Hoang and Yin, Pengyu and Cao, Haozhi and Xie, Lihua and Wozniak, Maciej and Jensfelt, Patric and Thiel, Marko and Ziegenbein, Justin and others}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{22304--22313}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/nguyen2022ntu-480.webp 480w,/assets/img/publication_preview/nguyen2022ntu-800.webp 800w,/assets/img/publication_preview/nguyen2022ntu-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/nguyen2022ntu.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nguyen2022ntu.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2022ntu" class="col-sm-8"> <div class="title">Ntu viral: A visual-inertial-ranging-lidar dataset, from an aerial vehicle viewpoint</div> <div class="author"> Thien-Minh Nguyen,¬†<em>Shenghai Yuan</em>,¬†Muqing Cao,¬†Yang Lyu,¬†Thien H Nguyen,¬†and¬†Lihua Xie </div> <div class="periodical"> <em>The International Journal of Robotics Research</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2022ntu</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Ntu viral: A visual-inertial-ranging-lidar dataset, from an aerial vehicle viewpoint}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Thien-Minh and Yuan, Shenghai and Cao, Muqing and Lyu, Yang and Nguyen, Thien H and Xie, Lihua}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The International Journal of Robotics Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{41}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{270--280}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{SAGE Publications Sage UK: London, England}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%73%68%79%75%61%6E@%6E%74%75.%65%64%75.%73%67" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0009-0003-1887-6342" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=XcV_sesAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Shenghai_Yuan/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://ieeexplore.ieee.org/author/37085527198#%20your%20ieeexplore.ieee.org/author/id/" title="IEEE Xplore" rel="external nofollow noopener" target="_blank"><i class="ai ai-ieee"></i></a> <a href="https://www.scopus.com/authid/detail.uri?authorId=55827000800#%20your%20profile%20on%20Scopus" title="Scopus" rel="external nofollow noopener" target="_blank"><i class="ai ai-scopus"></i></a> <a href="https://www.linkedin.com/in/shenghai-yuan-0613#%20your%20LinkedIn%20user%20name" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://dblp.org/pid/133/3411.html" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a> <a href="https://facebook.com/shenghai.yuan#%20your%20facebook%20id" title="Facebook" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-facebook"></i></a> <a href="https://youtube.com/@snakehaihai#%20your%20youtube%20channel%20id%20(youtube.com/@&lt;youtube_id&gt;)" title="YouTube" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-youtube"></i></a> <a id="WeChatBtn" title="WeChat"><i class="fa-brands fa-weixin"></i></a> <div id="WeChatMod" class="wechat-modal"> <img src="/assets/img/wechat.png" alt="WeChat QR" id="WeChatQR"> </div> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> </div> <div class="contact-note">I`m open to questions, collaborations, and academic job offers. Feel free to contact me by any ways. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Dr. Shenghai Yuan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/snakehaihai" rel="external nofollow noopener" target="_blank">snakehaihai</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"List of my publications in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"This is the CV for a modern roboticist.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-two-papers-are-accepted-by-icra-2023",title:"Two papers are accepted by ICRA 2023",description:"",section:"News"},{id:"news-three-papers-are-accepted-by-iros-2023",title:"Three papers are accepted by IROS 2023",description:"",section:"News"},{id:"news-one-paper-accepted-by-neurips-2023",title:"One paper accepted by NeurIPS 2023",description:"",section:"News"},{id:"news-four-papers-are-accepted-by-icra-2024",title:"Four papers are accepted by ICRA 2024",description:"",section:"News"},{id:"news-one-paper-accepted-by-cvpr-2024",title:"One paper accepted by CVPR 2024",description:"",section:"News"},{id:"news-track-5-of-the-7th-ug2-workshop-in-conjunction-with-cvpr-2024-has-been-completed-results-are-available-here-congratulations-to-all-the-winners",title:"Track 5 of the 7th UG2+ Workshop (in conjunction with CVPR 2024) has...",description:"",section:"News"},{id:"news-one-lio-paper-mm-lins-is-accepted-by-tiv",title:"One LIO paper \u201cMM-LINS\u201d is accepted by TIV",description:"",section:"News"},{id:"news-four-papers-are-accepted-by-iros-2024",title:"Four papers are accepted by IROS 2024",description:"",section:"News"},{id:"news-one-paper-accepted-by-tcst",title:"One paper accepted by TCST",description:"",section:"News"},{id:"news-organized-and-chair-of-iros-2024-workshop-on-multi-robot-perception-and-navigation-challenges-in-logistics-and-inspection-tasks-here-are-the-winning-teams-leaderboard-congratulations",title:"Organized and chair of IROS 2024 Workshop on Multi-Robot Perception and Navigation Challenges...",description:"",section:"News"},{id:"news-i-m-invited-to-serve-as-iros-chair-of-three-sessions",title:"I`m invited to serve as IROS chair of three sessions.",description:"",section:"News"},{id:"news-we-release-the-gptr-a-continuous-time-trajectory-representation-based-on-gaussian-process-for-motion-estimation-check-out-the-paper-and-the-source-code",title:"We release the GPTR, a continuous-time trajectory representation based on gaussian process for...",description:"",section:"News"},{id:"news-one-paper-robust-loop-closure-by-textual-cues-is-accepted-by-ral",title:"One paper \u201cRobust Loop Closure by Textual Cues\u201d is accepted by RAL",description:"",section:"News"},{id:"news-two-papers-accepted-by-icassp-2025",title:"Two papers accepted by ICASSP 2025",description:"",section:"News"},{id:"news-seven-papers-are-accepted-by-icra-2025",title:"Seven papers are accepted by ICRA 2025",description:"",section:"News"},{id:"news-two-papers-are-accepted-by-ieee-transactions-on-robotics-tro",title:"Two papers are accepted by IEEE Transactions on Robotics (TRO)",description:"",section:"News"},{id:"news-one-paper-has-been-accepted-by-cvpr-2025-thanks-to-my-collaborators-for-the-great-teamwork-i-have-also-been-recognized-as-an-outstanding-reviewer-for-cvpr-2025-thanks-to-the-cvpr-community-and-area-chairs-for-the-recognition",title:"\ud83c\udf89 One paper has been accepted by CVPR 2025. Thanks to my collaborators...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%68%79%75%61%6E@%6E%74%75.%65%64%75.%73%67","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0009-0003-1887-6342","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=XcV_sesAAAAJ","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Shenghai_Yuan/","_blank")}},{id:"socials-ieee-xplore",title:"IEEE Xplore",section:"Socials",handler:()=>{window.open("https://ieeexplore.ieee.org/author/37085527198# your ieeexplore.ieee.org/author/id/","_blank")}},{id:"socials-scopus",title:"Scopus",section:"Socials",handler:()=>{window.open("https://www.scopus.com/authid/detail.uri?authorId=55827000800# your profile on Scopus","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shenghai-yuan-0613# your LinkedIn user name","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/133/3411.html","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/shenghai.yuan# your facebook id","_blank")}},{id:"socials-youtube",title:"YouTube",section:"Socials",handler:()=>{window.open("https://youtube.com/@snakehaihai# your youtube channel id (youtube.com/@<youtube_id>)","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>